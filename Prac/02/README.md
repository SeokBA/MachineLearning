# 02. 텍스트 전처리(Text preprocessing)
#### 참고 : https://wikidocs.net/21694

전처리
- 용도에 맞게 텍스트를 사전에 처리하는 작업
- 자연어처리에서 크콜링 등으로 얻어낸 코퍼스 데이터가 전처리 되지 않은 상태라면, 용도에 맞게 토큰화 & 정제 & 정규화 함
-  코퍼스 : 말뭉치, 특정한 목적을 가지고 언어의 표본을 추출한 집단

토큰화
- 주어진 코퍼스에서 토큰이라 불리는 단위로 나누는 작업
- 토큰의 단위는 상황에 따라 다름, 의미있는 단위로 정함

단어 토큰화
- 토큰의 기준을 단어(또는 단어구, 의미를 갖는 문자열)로 하는 경우
- 단순히 구두점(. , ? ; !), 특수문자를 제거하는 정제 작업만으론 해결되지 않음
- 토큰화에서 고려해야할 사항
    1. 구두점이나 특수 문자를 단순 제외해서는 안된다
        - 정제 작업을 진행하다보면 구두점도 하나의 토큰이 될 수 있음 ex) .(온점)과 같은 경우 문장의 경계를 알 수 있는데 도움이 됨
        - 단어 자체에서 구두점을 갖고있는 경우도 있음 ex) Ph.D, 01/02/06, $45.55
    2. 줄임말이나 단어 내에 띄어쓰기가 있는 경우
        - 줄임말 ex) what're = whar are => 're'를 '접어'라고 함
        - 띄어쓰기 ex) New York, rock 'n' roll
- Penn Treebank Tokenization (표준 토큰화)
    1. 하이푼으로 구성된 단어는 하나로 유지한다.
    2. doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다.

문장 토큰화
- 토큰의 단위가 문장일 때
- 갖고있는 코퍼스 내에서 문장단위로 구분하는 작업, 문장 분류라고보 부름
- 갖고있는 코퍼스가 정제되지 않은 상태라면, 코퍼스는 문장 단위로 구분되어 있지 않을 가능성이 크므로 용도에 맞게 문장 토큰화 수행
- 단순히 구두점만으로 문장을 잘라내서는 안됨 ex) IP 192.168.56.31 서버에 들어가서 로그 파일 저장해서 ukairia777@gmail.com로 결과 좀 보내줘. 그러고나서 점심 먹으러 가자. => IP 192. 에서 잘리게 됨
- 따라서 사용하는 코퍼스의 언어 국적, 해당 코퍼스 내에서 특수문자들이 어떻게 사용되고 있는지에 따라 직접 규칙 정의해야 함

이진 분류기
- 문장 토큰화에서의 예외 사항을 발생시키는 온점의 처리를 위해서 입력에 따라 두 개의 클래스로 분류
- 두 개의 클래스
    1. 온점이 단어의 일부분일 경우
    2. 온점이 정말로 문장의 구분자일 경우
- 어떤 온점이 주로 약어로 쓰이는지 알아야 함 => 약어사전이 유용하게 쓰임
- 문장 토큰화 오픈소스 : NLTK, OpenNLP, 스탠포드 CoreNLP, splitta, LingPipe 등

한국어에서의 토큰화의 어려움
- 어절 : 띄어쓰기 단위가 되는 단위
- 한국어에서는 어절 토큰화 != 단어 토큰화
- 한국어는 영어와는 다른 형태인 교착어 : 조사, 어미등을 붙여서 말을 만드는 언어
1. 한국어는 교착어이다.
    - 조사(~가, ~에게, ~를)로 인해 주어나 목적어가 서로 다른 단어로 취급될 수 있음 ex) 그가, 그를, 그에게
    - 형태소 : 뜻을 가진 가장 작은 말의 단위
        1. 자립 형태소 : 접사, 어미, 조사와 상관 없이 자립하여 사용할 수 있는 형태소. 그 자체로도 단어가 됨 ex) 체언(명사, 대명사, 수사), 수식언(관형사, 부사), 감탄사 등
        2. 의존 형태소 : 다른 형태소와 결합하여 사용되는 형태소 ex) 접사, 어미, 조사, 어간
    - 한국어는 어절 토큰화가 아닌 형태소 토큰화를 수행해야 함
2. 한국어는 띄어쓰기가 영어보다 잘 지켜지지 않는다.
    - 영어에 비해 띄어쓰기가 어렵고, 잘 지켜지지 않음
    - 한국어는 띄어쓰기가 지켜지지 않아도 글을 쉽게 이해할 수 있음

품사 태깅
- 단어의 표기는 같지만 품사에 따라서 단어의 의미가 달라지기도 함 ex) fly(동사 : 날다, 명사 : 파리), 못(명사 : 목재 따위를 고정하는 물건, 부사 : 동작을 할 수 없음)
- 단어 토큰화 과정에서 각 단어가 어떤 품사로 쓰였는지 구분하는 것
